{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5\"\n",
    "\n",
    "import torch_influence\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_warn_always(False)\n",
    "\n",
    "from typing import List\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import yaml\n",
    "import lm_eval\n",
    "\n",
    "import datasets\n",
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import fire\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_kbit_training ,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = datasets.load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", cache_dir = \"./datasets\") # wikitext; evaluation broken DONE\n",
    "# print(\"wikitext\")\n",
    "# print(dataset)\n",
    "\n",
    "# dataset = datasets.load_dataset(\"trivia_qa\", \"rc\", cache_dir = \"./datasets\") # triviaQA DONE\n",
    "# print(\"trivia_qa\")\n",
    "# print(dataset)\n",
    "\n",
    "# dataset = datasets.load_dataset(\"bigbio/pubmed_qa\", cache_dir = \"./datasets\") # DONE\n",
    "# print(\"pubmed_qa\")\n",
    "# print(dataset)\n",
    "\n",
    "dataset = datasets.load_dataset(\"truthfulqa/truthful_qa\", \"generation\", cache_dir = \"./datasets\") # truthful QA # DONE\n",
    "print(\"truthful_qa\")\n",
    "print(dataset)\n",
    "\n",
    "dataset = datasets.load_dataset(\"tau/commonsense_qa\", cache_dir = \"./datasets\") # commonsense DONE\n",
    "print(\"commonsense_qa\")\n",
    "print(dataset)\n",
    "\n",
    "dataset = datasets.load_dataset(\"DatologyAI/hellaswag\", cache_dir = \"./datasets\", trust_remote_code=True) # hellaswag\n",
    "print(\"hellaswag\")\n",
    "print(dataset)\n",
    "\n",
    "# dataset = datasets.load_dataset(\"allenai/sciq\", cache_dir = \"./datasets\")\n",
    "# print(\"sciq\")\n",
    "# print(dataset)\n",
    "\n",
    "dataset = datasets.load_dataset(\"openai/gsm8k\", \"main\")\n",
    "print(\"gsm8k\")\n",
    "print(dataset)\n",
    "\n",
    "# dataset = datasets.load_dataset(\"rajpurkar/squad_v2\" , cache_dir = \"./datasets\") # DONE\n",
    "# print(\"squad_v2\")\n",
    "# print(dataset)\n",
    "\n",
    "# dataset = datasets.load_dataset(\"dvilares/head_qa\", cache_dir = \"./datasets\", trust_remote_code=True) # health QA\n",
    "# print(\"head_qa\")\n",
    "# print(dataset)\n",
    "\n",
    "# ['wikitext-103-raw-v1', 'wikitext-103-v1', 'wikitext-2-raw-v1', 'wikitext-2-v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsm8k\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 7473\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1319\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# dataset = datasets.load_dataset(\"truthfulqa/truthful_qa\", \"generation\", cache_dir = \"./datasets\") # truthful QA # DONE\n",
    "# print(\"truthful_qa\")\n",
    "# print(dataset)\n",
    "\n",
    "# dataset = datasets.load_dataset(\"tau/commonsense_qa\", cache_dir = \"./datasets\") # commonsense DONE\n",
    "# print(\"commonsense_qa\")\n",
    "# print(dataset)\n",
    "\n",
    "# dataset = datasets.load_dataset(\"DatologyAI/hellaswag\", cache_dir = \"./datasets\", trust_remote_code=True) # hellaswag\n",
    "# print(\"hellaswag\")\n",
    "# print(dataset)\n",
    "\n",
    "dataset = datasets.load_dataset(\"openai/gsm8k\", \"main\")\n",
    "print(\"gsm8k\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?',\n",
       " 'Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?',\n",
       " 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?',\n",
       " 'James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0:5]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06:16:39:37,828 INFO     [SentenceTransformer.py:218] Load pretrained SentenceTransformer: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.80it/s]\n",
      "2025-02-06:16:39:43,668 INFO     [SentenceTransformer.py:357] 1 prompts are loaded, with the keys: ['query']\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"Alibaba-NLP/gte-Qwen2-1.5B-instruct\", trust_remote_code=True, device=\"cpu\")\n",
    "model = model.to(\"cuda:4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import load_data\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "task_metrics = {\n",
    "  #\"commonsense_qa\": \"acc,none\",\n",
    "  \"gsm8k\": \"exact_match,strict-match\",\n",
    "  #\"headqa_en\": \"acc,none\",\n",
    "  #\"hellaswag\": \"acc,none\",\n",
    "  #\"pubmedqa\": \"acc,none\",\n",
    "  #\"sciq\": \"acc_norm,none\",\n",
    "  #\"triviaqa\": \"exact_match,remove_whitespace\",\n",
    "  #\"truthfulqa_gen\": \"bleu_acc,none\",\n",
    "  #\"wikitext\": \"word_perplexity,none\",\n",
    "}\n",
    "\n",
    "def embed(example):\n",
    "  try:\n",
    "    max_length = 32768\n",
    "    start = time.time()\n",
    "    text = example[\"text\"]\n",
    "    # if len(text) > 400:\n",
    "    #   text = text[:200]\n",
    "    passage_embeddings = model.encode([text])\n",
    "    # normalize embeddings\n",
    "    query_embeddings = normalize(passage_embeddings)\n",
    "  except:\n",
    "    assert False\n",
    "  return {\"embeddings\": query_embeddings}\n",
    "\n",
    "def extract_string(example):\n",
    "  return {\"text\": example[\"question\"]}\n",
    "  \n",
    "for task in task_metrics.keys():\n",
    "    train_dataset, val_dataset = load_data(data_domain=task)\n",
    "    \n",
    "    string_dataset_train = train_dataset.map(extract_string)\n",
    "    embed_dataset_train = string_dataset_train.map(embed)\n",
    "    output_embedding = np.array(embed_dataset_train[\"embeddings\"]).astype(str)\n",
    "    np.save(\"embeddings\" +str(task) + \".npy\", output_embedding)\n",
    "\n",
    "# LLM/domain_training_embeddings/commonsense_qa.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate= 3e-4\n",
    "cutoff_len = 256\n",
    "val_set_size = 2000\n",
    "# lora hyperparams\n",
    "lora_r = 8\n",
    "lora_alpha = 16\n",
    "lora_dropout= 0.05\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    "# llm hyperparams\n",
    "train_on_inputs = False  # if False, masks out inputs in loss\n",
    "add_eos_token = False\n",
    "group_by_length = False  # faster, but produces an odd training loss curve\n",
    "gradient_accumulation_steps = 1\n",
    "output_dir = \"LLM/\"\n",
    "use_wandb = False\n",
    "\n",
    "# Load the TrivialQA dataset\n",
    "dataset = datasets.load_dataset(\"trivia_qa\", \"rc\", cache_dir = \"./datasets\")\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "\n",
    "\n",
    "# get tokenizer and model\n",
    "tokenizer, model = get_tokenizer_and_model(model_id = \"LLM/llama_8b_instruct\")\n",
    "#model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# download data\n",
    "indices = range(0,1000)\n",
    "train_dataset = dataset[\"train\"].select(indices)\n",
    "val_dataset = dataset[\"validation\"].select(indices)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=lora_target_modules,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "\n",
    "model.print_trainable_parameters()  # Be more transparent about the % of trainable params.\n",
    "\n",
    "# apply tokenization to the data\n",
    "print(\"tokenizing data into correct format...\")\n",
    "train_data = (\n",
    "        train_dataset.shuffle().map(generate_and_tokenize_prompt_trivialQA)\n",
    "    )\n",
    "\n",
    "val_data = (\n",
    "        val_dataset.shuffle().map(generate_and_tokenize_prompt_trivialQA)\n",
    "    )\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=learning_rate,\n",
    "        bf16=True,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_torch\",\n",
    "        evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=100 if val_set_size > 0 else None,\n",
    "        save_steps=200,\n",
    "        output_dir=output_dir,\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True if val_set_size > 0 else False,\n",
    "        ddp_find_unused_parameters=True,\n",
    "        group_by_length=group_by_length,\n",
    "        report_to=\"wandb\"\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    ")\n",
    "print(\"begin to train...\")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mix-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
